# Project Vision: [PROJECT NAME]

**Created**: [DATE]
**Status**: Active
**Focus**: Goal-Driven Development

## üéØ Project Purpose

**Core Mission**: [What is the fundamental mission this project serves?]

**Vision Statement**: [Inspirational description of the future state this project aims to create]

**Target Outcomes**: [What specific outcomes should this project achieve?]

## üìä Success Metrics

### Primary Success Indicators

- **User Outcome 1**: [Measurable user benefit] - Target: [specific metric]
- **User Outcome 2**: [Measurable user benefit] - Target: [specific metric]
- **Business Outcome 1**: [Measurable business impact] - Target: [specific metric]
- **Business Outcome 2**: [Measurable business impact] - Target: [specific metric]

### Secondary Success Indicators

- **Learning Goals**: [What you want to discover through this project]
- **Innovation Goals**: [New approaches or insights to develop]
- **Capability Goals**: [New skills or expertise to build]

## üß≠ Guiding Principles

<!--
  AI GUIDANCE: Establish the core principles that will guide all development decisions.
  These principles should focus on outcomes, learning, and adaptation.
  Each principle should be actionable with clear decision-making guidance.
-->

### Principle 1: Outcome-First Thinking

Every decision must prioritize user and business outcomes over implementation preferences or technical elegance.
**AI Application**: When evaluating options, ask: "Which approach delivers more value to users and business?"

### Principle 2: Measurable Progress

All work must contribute to measurable progress toward defined success metrics.
**AI Application**: Before starting work, define: "What specific metric will this improve and by how much?"

### Principle 3: Strategy Flexibility

Multiple valid approaches exist for achieving any goal. Remain open to different strategies based on learning and results.
**AI Application**: Always consider at least 2-3 alternative approaches before committing to implementation.

### Principle 4: Learning Integration

Treat implementation as hypothesis testing. Every milestone should generate insights that inform future strategies.
**AI Application**: For each milestone, define: "What assumption are we testing and how will we measure the results?"

### Principle 5: Adaptive Planning

Plans are hypotheses to be tested, not contracts to be executed. Be willing to change course based on evidence.
**AI Application**: Establish clear pivot triggers: "Under what conditions would we change this approach?"

### Principle 6: Exploration Mindset

Embrace uncertainty as an opportunity for discovery. Multiple approaches should be explored before committing to a single path.
**AI Application**: Document multiple options for each major decision with pros/cons and validation criteria.

## üéØ Project Goals

<!--
  AI GUIDANCE: Define the high-level goals for this project.
  Each goal should have clear success criteria and measurable outcomes.
  Goals should be ambitious but achievable, with specific success thresholds.
-->

### Goal 1: [Goal Title]

**Description**: [What outcome this goal seeks to achieve. Format: "Enable [user type] to [specific action] resulting in [measurable benefit]"]

**Success Criteria**:

- [Measurable outcome 1 - include specific targets and timelines]
- [Measurable outcome 2 - include specific targets and timelines]
- [Measurable outcome 3 - include specific targets and timelines]

**Why Important**: [Why this goal matters to users and business. Connect to vision statement and target outcomes]

**Priority**: [P1-Critical | P2-High | P3-Medium | P4-Low] | **Effort**: [XS-1w | S-1m | M-3m | L-6m | XL-1y+]

### Goal 2: [Goal Title]

**Description**: [What outcome this goal seeks to achieve. Format: "Enable [user type] to [specific action] resulting in [measurable benefit]"]

**Success Criteria**:

- [Measurable outcome 1 - include specific targets and timelines]
- [Measurable outcome 2 - include specific targets and timelines]
- [Measurable outcome 3 - include specific targets and timelines]

**Why Important**: [Why this goal matters to users and business. Connect to vision statement and target outcomes]

**Priority**: [P1-Critical | P2-High | P3-Medium | P4-Low] | **Effort**: [XS-1w | S-1m | M-3m | L-6m | XL-1y+]

## üöÄ Project Scope

<!--
  AI GUIDANCE: Define what is included and excluded from this project.
  Focus on outcomes rather than specific features or implementations.
  Use this to set clear boundaries and manage expectations.
-->

### What's Included

- [Outcome or capability that will be delivered - be specific about user and business value]
- [User benefit that will be provided - connect to target outcomes]
- [Business value that will be created - link to success metrics]
- [Learning objectives that will be pursued - what discoveries are in scope]

### What's Explicitly Excluded

- [Outcomes or approaches that are out of scope - be clear about boundaries]
- [User needs that won't be addressed - manage expectations]
- [Technical approaches that won't be considered - avoid scope creep]
- [External dependencies not included - clarify what's not provided]

### Scope Management

- **Success Criteria**: [How to determine if scope is appropriate]
- **Expansion Triggers**: [Under what conditions scope might grow]
- **Reduction Triggers**: [When scope should be reduced]

## ‚è±Ô∏è Project Phases

<!--
  AI GUIDANCE: Define the high-level phases focused on learning and outcomes.
  Each phase should have clear entry/exit criteria and measurable success indicators.
-->

### Phase 1: Foundation (Exploration & Learning)

**Duration**: [Time estimate] | **Focus**: Discovery and setup

- Establish baseline understanding of users, market, and technical landscape
- Identify key assumptions to test and validate
- Create initial measurement framework and success metrics
- **Exit Criteria**: [Specific deliverables that complete this phase]

### Phase 2: Validation (Hypothesis Testing)

**Duration**: [Time estimate] | **Focus**: Testing core assumptions

- Test core assumptions with minimal viable implementations
- Measure actual vs expected outcomes against success metrics
- Learn from early user and business feedback
- **Exit Criteria**: [Specific validation results that complete this phase]

### Phase 3: Optimization (Strategy Refinement)

**Duration**: [Time estimate] | **Focus**: Refining based on learning

- Optimize based on learning from Phase 2 validation
- Explore alternative strategies where needed
- Scale successful approaches to broader user base
- **Exit Criteria**: [Specific optimization results that complete this phase]

### Phase 4: Expansion (Outcome Maximization)

**Duration**: [Time estimate] | **Focus**: Maximizing impact

- Expand to additional user segments or use cases
- Maximize outcomes based on proven strategies
- Document learning for future projects and teams
- **Exit Criteria**: [Specific expansion results that complete this phase]

### Phase Transition Criteria

- **Advancement Triggers**: [When to move from one phase to the next]
- **Regression Triggers**: [When to move back to earlier phases]
- **Pause Conditions**: [When to temporarily halt phase progression]

## üìà Measurement & Learning Framework

<!--
  AI GUIDANCE: Define how progress will be measured and learning captured.
  Include specific tools, processes, and success criteria for measurement.
-->

### Key Metrics to Track

- **Leading Indicators**: Early signals of progress toward goals - [Specific metrics and measurement frequency]
- **Lagging Indicators**: Final measures of goal achievement - [Specific metrics and measurement frequency]
- **Learning Metrics**: Indicators of insights and discoveries - [Specific metrics and measurement frequency]

### Learning Capture Process

- **Milestone Reviews**: Structured reflection at each milestone - [Specific review format and participants]
- **Strategy Assessments**: Evaluation of different approaches - [Assessment criteria and timing]
- **Pivot Decisions**: Framework for changing course when needed - [Decision criteria and approval process]

### Knowledge Documentation

- **What Worked**: Approaches and strategies that succeeded - [Documentation format and location]
- **What Didn't Work**: Failed approaches and why - [Documentation format and analysis]
- **Key Insights**: Important discoveries for future projects - [Documentation format and sharing process]

### Measurement Tools & Methods

- **Data Collection**: [Tools and processes for gathering metrics data]
- **Analysis Methods**: [How to analyze data and draw insights]
- **Reporting Cadence**: [How often to report progress and learnings]

## üîÑ Review & Adaptation Process

<!--
  AI GUIDANCE: Define how the project will adapt based on learning.
  Include specific triggers, decision criteria, and processes for adaptation.
-->

### Regular Review Cadence

- **Weekly**: Progress toward current milestones - [What to review, who attends, format]
- **Bi-weekly**: Strategy effectiveness and needed adjustments - [What to review, who attends, format]
- **Monthly**: Goal relevance and overall project direction - [What to review, who attends, format]

### Decision Framework for Changes

- **Continue**: When metrics show progress toward goals - [Specific indicators and thresholds]
- **Pivot**: When strategies aren't producing expected outcomes - [Specific triggers and decision process]
- **Pause**: When external factors require reassessment - [Specific conditions and restart criteria]
- **Stop**: When goals are achieved or no longer relevant - [Specific completion/termination criteria]

### Adaptation Process

- **Trigger Identification**: [How to identify when adaptation is needed]
- **Option Analysis**: [How to evaluate different adaptation approaches]
- **Decision Making**: [Who makes decisions and by what criteria]
- **Implementation**: [How to execute adaptations smoothly]

## üìù Success Criteria Validation

<!--
  AI GUIDANCE: Define how you'll know if this vision is successful.
  Include specific, measurable criteria for both success and failure.
-->

### Vision Success Indicators

- [ ] All primary success metrics achieved (specify exact targets and timelines)
- [ ] Learning goals accomplished (document specific insights gained)
- [ ] Project delivered measurable user and business value (quantify value created)
- [ ] Team developed new capabilities for future work (specify new skills/expertise)
- [ ] Project approach documented for future teams (create reusable templates/processes)
- [ ] Vision statement resonates with stakeholders (measure buy-in and alignment)

### Vision Failure Indicators

- [ ] Primary success metrics not achieved despite multiple strategies (define retry limits)
- [ ] Goals no longer relevant to user or business needs (track relevance over time)
- [ ] External factors make goals unachievable (monitor market/technical changes)
- [ ] Team unable to adapt strategies effectively (measure adaptation success rate)
- [ ] Project consumes excessive resources without proportional value (define ROI thresholds)

### Validation Timeline

- **Early Indicators**: [What to measure in first 4 weeks to validate direction]
- **Mid-point Validation**: [What to measure at 50% timeline to ensure on track]
- **Final Validation**: [What to measure at completion to confirm success]

## üéì Learning Goals

<!--
  AI GUIDANCE: Define what you want to learn from this project.
  Each learning goal should have clear success criteria and validation methods.
-->

### Technical Learning

- [What technical approaches or technologies to explore] - Success Criteria: [How to validate learning]
- [What architectural patterns to evaluate] - Success Criteria: [How to validate learning]
- [What implementation strategies to test] - Success Criteria: [How to validate learning]

### Process Learning

- [What development processes to improve] - Success Criteria: [How to validate learning]
- [What measurement approaches to validate] - Success Criteria: [How to validate learning]
- [What adaptation frameworks to develop] - Success Criteria: [How to validate learning]

### Business Learning

- [What business models or approaches to test] - Success Criteria: [How to validate learning]
- [What user behaviors or preferences to understand] - Success Criteria: [How to validate learning]
- [What market dynamics to explore] - Success Criteria: [How to validate learning]

### Learning Validation Framework

- **Capture Methods**: [How to document and organize learnings]
- **Validation Approaches**: [How to verify learning objectives are met]
- **Knowledge Transfer**: [How to share learnings with future teams]

---

*This vision document serves as the foundation for all goal-driven development activities. It should be reviewed and updated regularly as learning occurs and circumstances change.*
